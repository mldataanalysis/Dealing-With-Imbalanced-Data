{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this example I use NearMiss2 which is a method of imblearn. NearMiss2 belongs to the \n",
    "# family of under sampling methods used to address the imbalanced class problem.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "''' \n",
    "majority class : L  /  minority class : S \n",
    "Our goal is to maximise precision on the majority class and maximise recall on the minority\n",
    "class.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of class labels before resampling Counter({' L': 917, ' S': 121})\n",
      "Distribution of class labels after resampling Counter({' L': 242, ' S': 121})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\nearmiss.py:161: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn('The number of the samples to be selected is larger than'\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for the model.\n",
    "\n",
    "loc = r\"C:\\Users\\me\\Documents\\datasets\\yeast3.dat\"\n",
    "\n",
    "df = pd.read_csv(loc, sep=',', header=None)\n",
    "\n",
    "columns = ['mcg', 'gvh', 'alm', 'mit', 'erl', 'pox', 'vac', 'nuc', 'target']\n",
    "\n",
    "df.columns = columns\n",
    "\n",
    "df.target = df[\"target\"].str.replace('negative', 'L')\n",
    "df.target = df[\"target\"].str.replace('positive', 'S')\n",
    "\n",
    "y = df.target\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "y_train, y_test = np.asarray(y_train), np.asarray(y_test)\n",
    "\n",
    "us = NearMiss(ratio=0.5, size_ngh=3, version=2)\n",
    "X_train_res, y_train_res = us.fit_sample(X_train, y_train)\n",
    "\n",
    "print (\"Distribution of class labels before resampling {}\".format(Counter(y_train)))\n",
    "print (\"Distribution of class labels after resampling {}\".format(Counter(y_train_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train_res, X_test, y_train_res, y_test):\n",
    "    if __name__ == '__main__':\n",
    "        clf_base = LogisticRegression()\n",
    "        grid = {'C': 10.0 ** np.arange(-2, 3),\n",
    "                'penalty': ['l1', 'l2']}\n",
    "\n",
    "        cv = KFold(X_train.shape[0], n_folds=5, shuffle=True, random_state=0)\n",
    "        clf = GridSearchCV(clf_base, grid, cv=cv, n_jobs=-1, scoring='f1_macro')\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        coef = clf.best_estimator_.coef_\n",
    "        intercept = clf.best_estimator_.intercept_        \n",
    "\n",
    "        print (classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          L       0.97      0.99      0.98       404\n",
      "          S       0.83      0.69      0.75        42\n",
      "\n",
      "avg / total       0.96      0.96      0.96       446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model(X_train_res, X_test, y_train_res, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
